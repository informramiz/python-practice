{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_faces(f_cascade, colored_img):\n",
    "    img_copy = np.copy(colored_img)\n",
    "    #convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #let's detect multiscale (some images may be closer to camera than others) images\n",
    "    faces = f_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5);\n",
    "    \n",
    "    #go over list of faces and draw them as rectangles on original colored img\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img_copy, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/1/x64/conda-bld/work/opencv-3.1.0/modules/videoio/src/cap_mjpeg_encoder.cpp:829: error: (-215) img.cols == width && img.rows == height && channels == 3 in function write\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a4725e129523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m#write the face detected image to output video file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mvideo_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/1/x64/conda-bld/work/opencv-3.1.0/modules/videoio/src/cap_mjpeg_encoder.cpp:829: error: (-215) img.cols == width && img.rows == height && channels == 3 in function write\n"
     ]
    }
   ],
   "source": [
    "#load cascade classifier training file for haarcascade\n",
    "face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "#Acquire default webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "#Define the codec and create VideoWriter object for writing video to a file\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "video_writer = cv2.VideoWriter('face_tracking_output.avi',fourcc, 20.0, (720, 1280))\n",
    "\n",
    "while(True):\n",
    "    #let's capture video frame by frame\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    #break loop if video capture failed\n",
    "    if ret == False:\n",
    "        break;\n",
    "    \n",
    "    #detect faces\n",
    "    face_detected_img = detect_faces(face_cascade, frame)\n",
    "    #show face detected image\n",
    "    cv2.imshow('video', face_detected_img)\n",
    "    \n",
    "    #write the face detected image to output video file\n",
    "    frame = cv2.flip(frame,0)\n",
    "    video_writer.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release everything when you are done\n",
    "video_capture.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<pre>\n",
    "```\n",
    "| This | is   |\n",
    "|------|------|\n",
    "|   a  | table|\n",
    "```\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
